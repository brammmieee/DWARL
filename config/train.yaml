# Configuration for training a model with callbacks, model settings, etc.
generate_data: true
steps: 10000000             # number of training steps
envs: 6    # number of parallel environments (and Webots instances)
log_interval: 10            # logging interval for logging callback parsed to model [steps]
callbacks:
  model_eval_freq: 10000      # model evaluation frequency [steps]
  model_n_eval_episodes: 25   # number of episodes for model evaluation [episodes]
  model_save_freq: 10000      # model saving frequency [steps]
model:
  policy_type: MlpPolicy            # policy type for the neural network
  activation_fn: ReLU         # activation function for the neural network
  net_arch:                         # network architecture for the neural network
    pi: [256, 256, 256, 256, 256]     # policy network architecture
    vf: [256, 256, 256, 256, 256]     # value function network architecture

# Included configuration (Hydra creates a single configuration from the included files)
defaults:
- _self_
- environment:
    - cindy
- wrappers: # order matters
    - sparse_lidar_observation
    - command_velocity_action
    # - time_limit
- data_generator:
    - cindy
- simulation:
    - webots

# System paths used throughout
paths:
  root: ${hydra:runtime.cwd}
  tmp: /tmp/DWARL
  resources: 
    maps: ${paths.root}/resources/maps
    paths: ${paths.root}/resources/paths
    map_name_lists: ${paths.root}/resources/map_name_lists
    protos: ${paths.root}/resources/protos
    worlds: ${paths.root}/resources/worlds
  outputs:
    logs: ${hydra:runtime.output_dir}/logs
    models: ${hydra:runtime.output_dir}/models
    data_generator_logs: ${hydra:runtime.output_dir}/data_generator_logs
  data_sets:
    root: ${paths.tmp}/data_sets
    paths: ${paths.data_sets.root}/paths
    maps: ${paths.data_sets.root}/maps
    data_points: ${paths.data_sets.root}/data_points
  sim_resources:
    root: ${paths.tmp}/sim_resources
    worlds: ${paths.sim_resources.root}/worlds
    protos: ${paths.sim_resources.root}/protos